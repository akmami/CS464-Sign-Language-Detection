 Execution of ANN training without drop out and with relu

Epoch 1/50
687/687 [==============================] - 10s 14ms/step - loss: 1.7816 - sparse_categorical_accuracy: 0.4354 - val_loss: 1.0198 - val_sparse_categorical_accuracy: 0.6729
Epoch 2/50
687/687 [==============================] - 10s 14ms/step - loss: 0.7632 - sparse_categorical_accuracy: 0.7494 - val_loss: 0.5289 - val_sparse_categorical_accuracy: 0.8233
Epoch 3/50
687/687 [==============================] - 10s 14ms/step - loss: 0.3960 - sparse_categorical_accuracy: 0.8691 - val_loss: 0.2513 - val_sparse_categorical_accuracy: 0.9273
Epoch 4/50
687/687 [==============================] - 10s 14ms/step - loss: 0.2253 - sparse_categorical_accuracy: 0.9287 - val_loss: 0.1516 - val_sparse_categorical_accuracy: 0.9497
Epoch 5/50
687/687 [==============================] - 10s 15ms/step - loss: 0.1711 - sparse_categorical_accuracy: 0.9454 - val_loss: 0.1818 - val_sparse_categorical_accuracy: 0.9357
Epoch 6/50
687/687 [==============================] - 10s 14ms/step - loss: 0.1227 - sparse_categorical_accuracy: 0.9619 - val_loss: 0.0605 - val_sparse_categorical_accuracy: 0.9863
Epoch 7/50
687/687 [==============================] - 10s 14ms/step - loss: 0.1149 - sparse_categorical_accuracy: 0.9668 - val_loss: 0.4643 - val_sparse_categorical_accuracy: 0.8363
Epoch 8/50
687/687 [==============================] - 10s 15ms/step - loss: 0.0697 - sparse_categorical_accuracy: 0.9798 - val_loss: 0.4308 - val_sparse_categorical_accuracy: 0.8472
Epoch 9/50
687/687 [==============================] - 10s 14ms/step - loss: 0.0917 - sparse_categorical_accuracy: 0.9723 - val_loss: 0.1055 - val_sparse_categorical_accuracy: 0.9690
Epoch 10/50
687/687 [==============================] - 10s 14ms/step - loss: 0.0386 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.0061 - val_sparse_categorical_accuracy: 0.9998
Epoch 11/50
687/687 [==============================] - 10s 15ms/step - loss: 0.0653 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.1181 - val_sparse_categorical_accuracy: 0.9574
Epoch 12/50
687/687 [==============================] - 10s 15ms/step - loss: 0.0433 - sparse_categorical_accuracy: 0.9865 - val_loss: 0.0013 - val_sparse_categorical_accuracy: 1.0000
Epoch 13/50
687/687 [==============================] - 10s 14ms/step - loss: 0.0011 - sparse_categorical_accuracy: 1.0000 - val_loss: 8.4324e-04 - val_sparse_categorical_accuracy: 1.0000
Epoch 14/50
687/687 [==============================] - 10s 15ms/step - loss: 7.0653e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 6.5420e-04 - val_sparse_categorical_accuracy: 1.0000
Epoch 15/50
687/687 [==============================] - 9s 13ms/step - loss: 0.1700 - sparse_categorical_accuracy: 0.9526 - val_loss: 0.0554 - val_sparse_categorical_accuracy: 0.9822
Epoch 16/50
687/687 [==============================] - 10s 14ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9992 - val_loss: 0.0190 - val_sparse_categorical_accuracy: 0.9965
Epoch 17/50
687/687 [==============================] - 9s 14ms/step - loss: 0.0592 - sparse_categorical_accuracy: 0.9819 - val_loss: 0.0029 - val_sparse_categorical_accuracy: 1.0000
Model: "ANN_without_dropout_and_with_relu"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 Hidden_Layer_1 (Dense)      (None, 1024)              803840    
                                                                 
 Hidden_Layer_2 (Dense)      (None, 512)               524800    
                                                                 
 Output_Layer (Dense)        (None, 24)                12312     
                                                                 
=================================================================
Total params: 1,340,952
Trainable params: 1,340,952
Non-trainable params: 0
_________________________________________________________________
End of training model with activation function =  relu
--------------------------------------------------------------------------------------

              precision    recall  f1-score   support

           0       0.81      1.00      0.90       331
           1       0.99      0.93      0.96       432
           2       1.00      0.93      0.96       310
           3       0.85      0.97      0.91       245
           4       0.91      1.00      0.95       498
           5       0.78      1.00      0.88       247
           6       0.91      0.79      0.84       348
           7       0.95      0.95      0.95       436
           8       0.82      0.93      0.87       288
           9       0.91      0.60      0.73       331
          10       0.78      1.00      0.88       209
          11       0.80      0.69      0.74       394
          12       0.86      0.64      0.74       291
          13       1.00      0.82      0.90       246
          14       0.95      1.00      0.97       347
          15       0.76      0.83      0.79       164
          16       0.53      0.80      0.64       144
          17       0.66      0.65      0.65       246
          18       0.66      0.67      0.66       248
          19       0.60      0.55      0.57       266
          20       0.83      0.76      0.80       346
          21       0.62      0.74      0.68       206
          22       0.77      0.83      0.80       267
          23       0.85      0.68      0.76       332

    accuracy                           0.83      7172
   macro avg       0.82      0.82      0.81      7172
weighted avg       0.84      0.83      0.83      7172

Execution of ANN training without drop out and with PReLU

Epoch 1/50
687/687 [==============================] - 11s 15ms/step - loss: 1.7216 - sparse_categorical_accuracy: 0.4542 - val_loss: 0.9833 - val_sparse_categorical_accuracy: 0.6487
Epoch 2/50
687/687 [==============================] - 10s 15ms/step - loss: 0.6689 - sparse_categorical_accuracy: 0.7746 - val_loss: 0.3372 - val_sparse_categorical_accuracy: 0.9031
Epoch 3/50
687/687 [==============================] - 11s 16ms/step - loss: 0.3150 - sparse_categorical_accuracy: 0.8974 - val_loss: 0.1228 - val_sparse_categorical_accuracy: 0.9701
Epoch 4/50
687/687 [==============================] - 10s 14ms/step - loss: 0.1685 - sparse_categorical_accuracy: 0.9460 - val_loss: 0.1522 - val_sparse_categorical_accuracy: 0.9523
Epoch 5/50
687/687 [==============================] - 10s 14ms/step - loss: 0.1406 - sparse_categorical_accuracy: 0.9532 - val_loss: 0.0910 - val_sparse_categorical_accuracy: 0.9705
Epoch 6/50
687/687 [==============================] - 10s 14ms/step - loss: 0.0973 - sparse_categorical_accuracy: 0.9692 - val_loss: 0.1423 - val_sparse_categorical_accuracy: 0.9488
Epoch 7/50
687/687 [==============================] - 10s 14ms/step - loss: 0.0276 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.0101 - val_sparse_categorical_accuracy: 0.9982
Epoch 8/50
687/687 [==============================] - 10s 14ms/step - loss: 0.1640 - sparse_categorical_accuracy: 0.9458 - val_loss: 0.1998 - val_sparse_categorical_accuracy: 0.9337
Epoch 9/50
687/687 [==============================] - 10s 15ms/step - loss: 0.0073 - sparse_categorical_accuracy: 0.9984 - val_loss: 0.0010 - val_sparse_categorical_accuracy: 1.0000
Epoch 10/50
687/687 [==============================] - 10s 14ms/step - loss: 8.3593e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 6.3991e-04 - val_sparse_categorical_accuracy: 1.0000
Epoch 11/50
687/687 [==============================] - 11s 15ms/step - loss: 5.5168e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 5.0015e-04 - val_sparse_categorical_accuracy: 1.0000
Epoch 12/50
687/687 [==============================] - 10s 15ms/step - loss: 4.4000e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.2029e-04 - val_sparse_categorical_accuracy: 1.0000
Epoch 13/50
687/687 [==============================] - 10s 15ms/step - loss: 0.2332 - sparse_categorical_accuracy: 0.9490 - val_loss: 0.1692 - val_sparse_categorical_accuracy: 0.9414
Epoch 14/50
687/687 [==============================] - 10s 15ms/step - loss: 0.0283 - sparse_categorical_accuracy: 0.9912 - val_loss: 0.0012 - val_sparse_categorical_accuracy: 1.0000
Epoch 15/50
687/687 [==============================] - 10s 15ms/step - loss: 7.8926e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 6.1704e-04 - val_sparse_categorical_accuracy: 1.0000
Model: "ANN_without_dropout_and_with_PReLU"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 Hidden_Layer_1 (Dense)      (None, 1024)              804864    
                                                                 
 Hidden_Layer_2 (Dense)      (None, 512)               525312    
                                                                 
 Output_Layer (Dense)        (None, 24)                12312     
                                                                 
=================================================================
Total params: 1,342,488
Trainable params: 1,342,488
Non-trainable params: 0
_________________________________________________________________
End of training model with activation function =  PReLU
--------------------------------------------------------------------------------------

              precision    recall  f1-score   support

           0       0.81      1.00      0.89       331
           1       1.00      1.00      1.00       432
           2       0.91      0.98      0.94       310
           3       0.86      0.92      0.89       245
           4       0.90      1.00      0.94       498
           5       0.84      0.99      0.91       247
           6       0.88      0.87      0.88       348
           7       0.96      0.91      0.93       436
           8       0.91      0.78      0.84       288
           9       0.96      0.65      0.77       331
          10       0.77      1.00      0.87       209
          11       0.80      0.78      0.79       394
          12       0.87      0.57      0.69       291
          13       0.99      0.83      0.90       246
          14       0.94      0.98      0.96       347
          15       0.73      0.90      0.80       164
          16       0.67      0.72      0.69       144
          17       0.76      0.55      0.64       246
          18       0.77      0.67      0.72       248
          19       0.73      0.66      0.69       266
          20       0.67      0.72      0.70       346
          21       0.58      0.80      0.67       206
          22       0.68      0.81      0.74       267
          23       0.83      0.72      0.77       332

    accuracy                           0.84      7172
   macro avg       0.83      0.82      0.82      7172
weighted avg       0.84      0.84      0.83      7172

Execution of ANN training without drop out and with sigmoid

Epoch 1/50
687/687 [==============================] - 11s 15ms/step - loss: 1.9655 - sparse_categorical_accuracy: 0.3829 - val_loss: 1.3131 - val_sparse_categorical_accuracy: 0.5531
Epoch 2/50
687/687 [==============================] - 10s 14ms/step - loss: 0.9378 - sparse_categorical_accuracy: 0.6937 - val_loss: 0.7942 - val_sparse_categorical_accuracy: 0.7408
Epoch 3/50
687/687 [==============================] - 9s 13ms/step - loss: 0.5731 - sparse_categorical_accuracy: 0.8185 - val_loss: 0.4035 - val_sparse_categorical_accuracy: 0.8634
Epoch 4/50
687/687 [==============================] - 9s 14ms/step - loss: 0.3252 - sparse_categorical_accuracy: 0.9057 - val_loss: 0.3216 - val_sparse_categorical_accuracy: 0.8864
Epoch 5/50
687/687 [==============================] - 10s 14ms/step - loss: 0.2001 - sparse_categorical_accuracy: 0.9451 - val_loss: 0.1132 - val_sparse_categorical_accuracy: 0.9818
Epoch 6/50
687/687 [==============================] - 9s 13ms/step - loss: 0.1145 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0489 - val_sparse_categorical_accuracy: 0.9964
Epoch 7/50
687/687 [==============================] - 9s 13ms/step - loss: 0.0879 - sparse_categorical_accuracy: 0.9786 - val_loss: 0.1043 - val_sparse_categorical_accuracy: 0.9658
Epoch 8/50
687/687 [==============================] - 9s 13ms/step - loss: 0.0670 - sparse_categorical_accuracy: 0.9834 - val_loss: 0.0601 - val_sparse_categorical_accuracy: 0.9858
Epoch 9/50
687/687 [==============================] - 9s 13ms/step - loss: 0.0678 - sparse_categorical_accuracy: 0.9822 - val_loss: 0.0194 - val_sparse_categorical_accuracy: 0.9993
Epoch 10/50
687/687 [==============================] - 9s 14ms/step - loss: 0.0086 - sparse_categorical_accuracy: 0.9998 - val_loss: 0.0057 - val_sparse_categorical_accuracy: 1.0000
Epoch 11/50
687/687 [==============================] - 9s 13ms/step - loss: 0.0981 - sparse_categorical_accuracy: 0.9727 - val_loss: 0.0074 - val_sparse_categorical_accuracy: 1.0000
Epoch 12/50
687/687 [==============================] - 10s 14ms/step - loss: 0.0088 - sparse_categorical_accuracy: 0.9992 - val_loss: 0.0059 - val_sparse_categorical_accuracy: 1.0000
Epoch 13/50
687/687 [==============================] - 10s 14ms/step - loss: 0.0822 - sparse_categorical_accuracy: 0.9732 - val_loss: 0.0184 - val_sparse_categorical_accuracy: 0.9987
Model: "ANN_without_dropout_and_with_sigmoid"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 Hidden_Layer_1 (Dense)      (None, 1024)              803840    
                                                                 
 Hidden_Layer_2 (Dense)      (None, 512)               524800    
                                                                 
 Output_Layer (Dense)        (None, 24)                12312     
                                                                 
=================================================================
Total params: 1,340,952
Trainable params: 1,340,952
Non-trainable params: 0
_________________________________________________________________
End of training model with activation function =  sigmoid
--------------------------------------------------------------------------------------

              precision    recall  f1-score   support

           0       0.88      0.97      0.93       331
           1       0.99      0.97      0.98       432
           2       0.71      0.99      0.83       310
           3       0.96      0.87      0.91       245
           4       0.92      0.95      0.94       498
           5       0.90      0.91      0.91       247
           6       0.81      0.93      0.87       348
           7       1.00      0.91      0.95       436
           8       0.83      0.78      0.80       288
           9       0.79      0.70      0.74       331
          10       0.71      0.91      0.80       209
          11       0.82      0.79      0.80       394
          12       0.78      0.60      0.68       291
          13       1.00      0.66      0.80       246
          14       0.94      0.94      0.94       347
          15       0.70      0.88      0.78       164
          16       0.51      0.56      0.53       144
          17       0.52      0.56      0.54       246
          18       0.74      0.69      0.71       248
          19       0.69      0.50      0.58       266
          20       0.68      0.64      0.66       346
          21       0.58      0.81      0.68       206
          22       0.74      0.89      0.81       267
          23       0.91      0.67      0.77       332

    accuracy                           0.81      7172
   macro avg       0.80      0.80      0.79      7172
weighted avg       0.82      0.81      0.81      7172

Train time(secs) without dropout relu 	167.58163785934448
Train time(secs) without dropout PReLU 	153.41403079032898
Train time(secs) without dropout sigmoid 	124.03638672828674