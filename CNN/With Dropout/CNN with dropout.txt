Execution of CNN training with drop out and with relu

Model: "CNN_with_dropout_and_with_relu"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 first_filters (Conv2D)      (None, 26, 26, 3)         30        
                                                                 
 batch_normalization_4 (Batc  (None, 26, 26, 3)        12        
 hNormalization)                                                 
                                                                 
 MaxPool1 (MaxPooling2D)     (None, 13, 13, 3)         0         
                                                                 
 second_filters (Conv2D)     (None, 11, 11, 3)         84        
                                                                 
 batch_normalization_5 (Batc  (None, 11, 11, 3)        12        
 hNormalization)                                                 
                                                                 
 MaxPool2 (MaxPooling2D)     (None, 5, 5, 3)           0         
                                                                 
 Flatten_of_Convs_Output (Fl  (None, 75)               0         
 atten)                                                          
                                                                 
 Hidden_Layer_1 (Dense)      (None, 1024)              77824     
                                                                 
 Dropout_1 (Dropout)         (None, 1024)              0         
                                                                 
 Hidden_Layer_2 (Dense)      (None, 512)               524800    
                                                                 
 Dropout_2 (Dropout)         (None, 512)               0         
                                                                 
 Output_Layer (Dense)        (None, 24)                12312     
                                                                 
=================================================================
Total params: 615,074
Trainable params: 615,062
Non-trainable params: 12
_________________________________________________________________
Epoch 1/50
687/687 [==============================] - 15s 21ms/step - loss: 0.4361 - sparse_categorical_accuracy: 0.8690 - val_loss: 0.0251 - val_sparse_categorical_accuracy: 0.9971
Epoch 2/50
687/687 [==============================] - 14s 20ms/step - loss: 0.0296 - sparse_categorical_accuracy: 0.9929 - val_loss: 0.0350 - val_sparse_categorical_accuracy: 0.9874
Epoch 3/50
687/687 [==============================] - 12s 18ms/step - loss: 0.0271 - sparse_categorical_accuracy: 0.9922 - val_loss: 0.0014 - val_sparse_categorical_accuracy: 0.9998
Epoch 4/50
687/687 [==============================] - 12s 18ms/step - loss: 0.0321 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0464 - val_sparse_categorical_accuracy: 0.9860
Epoch 5/50
687/687 [==============================] - 13s 18ms/step - loss: 0.0106 - sparse_categorical_accuracy: 0.9976 - val_loss: 3.4828e-04 - val_sparse_categorical_accuracy: 1.0000
Epoch 6/50
687/687 [==============================] - 12s 18ms/step - loss: 0.0092 - sparse_categorical_accuracy: 0.9971 - val_loss: 0.0637 - val_sparse_categorical_accuracy: 0.9851
Epoch 7/50
687/687 [==============================] - 12s 18ms/step - loss: 0.0322 - sparse_categorical_accuracy: 0.9901 - val_loss: 0.0084 - val_sparse_categorical_accuracy: 0.9967
Epoch 8/50
687/687 [==============================] - 12s 18ms/step - loss: 0.0128 - sparse_categorical_accuracy: 0.9973 - val_loss: 0.0022 - val_sparse_categorical_accuracy: 0.9991
Epoch 9/50
687/687 [==============================] - 12s 18ms/step - loss: 0.0123 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.0412 - val_sparse_categorical_accuracy: 0.9856
End of training model with activation function =  relu
--------------------------------------------------------------------------------------

              precision    recall  f1-score   support

           0       0.94      0.96      0.95       331
           1       0.99      0.91      0.95       432
           2       0.99      1.00      1.00       310
           3       0.78      0.86      0.82       245
           4       0.91      0.88      0.90       498
           5       0.79      0.92      0.85       247
           6       0.90      0.80      0.85       348
           7       0.94      0.77      0.85       436
           8       0.69      0.87      0.77       288
           9       0.99      0.73      0.84       331
          10       0.58      1.00      0.73       209
          11       0.90      0.58      0.71       394
          12       0.64      0.71      0.68       291
          13       0.93      0.67      0.78       246
          14       0.96      0.94      0.95       347
          15       0.76      1.00      0.86       164
          16       0.58      0.18      0.28       144
          17       0.49      0.86      0.62       246
          18       0.92      0.59      0.72       248
          19       0.76      0.77      0.77       266
          20       0.88      0.82      0.85       346
          21       0.60      0.89      0.72       206
          22       0.78      0.64      0.70       267
          23       0.78      0.90      0.84       332

    accuracy                           0.81      7172
   macro avg       0.81      0.80      0.79      7172
weighted avg       0.84      0.81      0.81      7172

Execution of CNN training with drop out and with PReLU

Model: "CNN_with_dropout_and_with_PReLU"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 first_filters (Conv2D)      (None, 26, 26, 3)         30        
                                                                 
 batch_normalization_6 (Batc  (None, 26, 26, 3)        12        
 hNormalization)                                                 
                                                                 
 MaxPool1 (MaxPooling2D)     (None, 13, 13, 3)         0         
                                                                 
 second_filters (Conv2D)     (None, 11, 11, 3)         84        
                                                                 
 batch_normalization_7 (Batc  (None, 11, 11, 3)        12        
 hNormalization)                                                 
                                                                 
 MaxPool2 (MaxPooling2D)     (None, 5, 5, 3)           0         
                                                                 
 Flatten_of_Convs_Output (Fl  (None, 75)               0         
 atten)                                                          
                                                                 
 Hidden_Layer_1 (Dense)      (None, 1024)              78848     
                                                                 
 Dropout_1 (Dropout)         (None, 1024)              0         
                                                                 
 Hidden_Layer_2 (Dense)      (None, 512)               525312    
                                                                 
 Dropout_2 (Dropout)         (None, 512)               0         
                                                                 
 Output_Layer (Dense)        (None, 24)                12312     
                                                                 
=================================================================
Total params: 616,610
Trainable params: 616,598
Non-trainable params: 12
_________________________________________________________________
Epoch 1/50
687/687 [==============================] - 15s 20ms/step - loss: 0.4430 - sparse_categorical_accuracy: 0.8647 - val_loss: 0.0661 - val_sparse_categorical_accuracy: 0.9834
Epoch 2/50
687/687 [==============================] - 14s 20ms/step - loss: 0.0373 - sparse_categorical_accuracy: 0.9898 - val_loss: 0.0411 - val_sparse_categorical_accuracy: 0.9876
Epoch 3/50
687/687 [==============================] - 14s 21ms/step - loss: 0.0291 - sparse_categorical_accuracy: 0.9911 - val_loss: 0.0072 - val_sparse_categorical_accuracy: 0.9980
Epoch 4/50
687/687 [==============================] - 14s 21ms/step - loss: 0.0291 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0287 - val_sparse_categorical_accuracy: 0.9920
Epoch 5/50
687/687 [==============================] - 15s 21ms/step - loss: 0.0156 - sparse_categorical_accuracy: 0.9958 - val_loss: 0.0099 - val_sparse_categorical_accuracy: 0.9975
Epoch 6/50
687/687 [==============================] - 14s 20ms/step - loss: 0.0317 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0480 - val_sparse_categorical_accuracy: 0.9902
Epoch 7/50
687/687 [==============================] - 14s 20ms/step - loss: 0.0153 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0040 - val_sparse_categorical_accuracy: 0.9985
Epoch 8/50
687/687 [==============================] - 14s 20ms/step - loss: 0.0179 - sparse_categorical_accuracy: 0.9950 - val_loss: 0.0019 - val_sparse_categorical_accuracy: 0.9993
Epoch 9/50
687/687 [==============================] - 14s 20ms/step - loss: 0.0184 - sparse_categorical_accuracy: 0.9949 - val_loss: 0.0147 - val_sparse_categorical_accuracy: 0.9940
Epoch 10/50
687/687 [==============================] - 14s 20ms/step - loss: 0.0224 - sparse_categorical_accuracy: 0.9941 - val_loss: 0.0045 - val_sparse_categorical_accuracy: 0.9982
End of training model with activation function =  PReLU
--------------------------------------------------------------------------------------

              precision    recall  f1-score   support

           0       0.96      0.95      0.95       331
           1       1.00      0.91      0.95       432
           2       0.89      0.94      0.91       310
           3       0.81      1.00      0.89       245
           4       0.96      1.00      0.98       498
           5       0.85      1.00      0.92       247
           6       0.86      0.77      0.81       348
           7       0.85      0.91      0.88       436
           8       0.88      0.92      0.90       288
           9       0.80      0.91      0.85       331
          10       0.90      0.95      0.92       209
          11       0.93      0.66      0.77       394
          12       0.73      0.73      0.73       291
          13       1.00      0.82      0.90       246
          14       0.98      0.76      0.86       347
          15       0.79      1.00      0.88       164
          16       0.59      0.56      0.57       144
          17       0.71      0.88      0.79       246
          18       0.88      0.62      0.73       248
          19       0.61      0.68      0.64       266
          20       0.99      0.80      0.88       346
          21       0.87      1.00      0.93       206
          22       0.80      0.85      0.83       267
          23       0.83      0.94      0.88       332

    accuracy                           0.86      7172
   macro avg       0.85      0.86      0.85      7172
weighted avg       0.87      0.86      0.86      7172

Execution of CNN training with drop out and with sigmoid

Model: "CNN_with_dropout_and_with_sigmoid"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 first_filters (Conv2D)      (None, 26, 26, 3)         30        
                                                                 
 batch_normalization_8 (Batc  (None, 26, 26, 3)        12        
 hNormalization)                                                 
                                                                 
 MaxPool1 (MaxPooling2D)     (None, 13, 13, 3)         0         
                                                                 
 second_filters (Conv2D)     (None, 11, 11, 3)         84        
                                                                 
 batch_normalization_9 (Batc  (None, 11, 11, 3)        12        
 hNormalization)                                                 
                                                                 
 MaxPool2 (MaxPooling2D)     (None, 5, 5, 3)           0         
                                                                 
 Flatten_of_Convs_Output (Fl  (None, 75)               0         
 atten)                                                          
                                                                 
 Hidden_Layer_1 (Dense)      (None, 1024)              77824     
                                                                 
 Dropout_1 (Dropout)         (None, 1024)              0         
                                                                 
 Hidden_Layer_2 (Dense)      (None, 512)               524800    
                                                                 
 Dropout_2 (Dropout)         (None, 512)               0         
                                                                 
 Output_Layer (Dense)        (None, 24)                12312     
                                                                 
=================================================================
Total params: 615,074
Trainable params: 615,062
Non-trainable params: 12
_________________________________________________________________
Epoch 1/50
687/687 [==============================] - 14s 19ms/step - loss: 1.2669 - sparse_categorical_accuracy: 0.6137 - val_loss: 0.4645 - val_sparse_categorical_accuracy: 0.8660
Epoch 2/50
687/687 [==============================] - 13s 19ms/step - loss: 0.2872 - sparse_categorical_accuracy: 0.9132 - val_loss: 0.1684 - val_sparse_categorical_accuracy: 0.9583
Epoch 3/50
687/687 [==============================] - 13s 19ms/step - loss: 0.0909 - sparse_categorical_accuracy: 0.9797 - val_loss: 0.0373 - val_sparse_categorical_accuracy: 0.9954
Epoch 4/50
687/687 [==============================] - 13s 19ms/step - loss: 0.0342 - sparse_categorical_accuracy: 0.9951 - val_loss: 0.0137 - val_sparse_categorical_accuracy: 0.9987
Epoch 5/50
687/687 [==============================] - 13s 19ms/step - loss: 0.0176 - sparse_categorical_accuracy: 0.9977 - val_loss: 0.0278 - val_sparse_categorical_accuracy: 0.9933
Epoch 6/50
687/687 [==============================] - 13s 19ms/step - loss: 0.0113 - sparse_categorical_accuracy: 0.9983 - val_loss: 0.0311 - val_sparse_categorical_accuracy: 0.9940
Epoch 7/50
687/687 [==============================] - 13s 19ms/step - loss: 0.0081 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0047 - val_sparse_categorical_accuracy: 0.9996
Epoch 8/50
687/687 [==============================] - 16s 23ms/step - loss: 0.0077 - sparse_categorical_accuracy: 0.9986 - val_loss: 0.0025 - val_sparse_categorical_accuracy: 0.9993
Epoch 9/50
687/687 [==============================] - 17s 25ms/step - loss: 0.0075 - sparse_categorical_accuracy: 0.9980 - val_loss: 0.0046 - val_sparse_categorical_accuracy: 0.9989
Epoch 10/50
687/687 [==============================] - 15s 22ms/step - loss: 0.0060 - sparse_categorical_accuracy: 0.9985 - val_loss: 0.0013 - val_sparse_categorical_accuracy: 0.9996
Epoch 11/50
687/687 [==============================] - 13s 20ms/step - loss: 0.0029 - sparse_categorical_accuracy: 0.9993 - val_loss: 0.0033 - val_sparse_categorical_accuracy: 0.9989
Epoch 12/50
687/687 [==============================] - 14s 20ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9978 - val_loss: 0.0504 - val_sparse_categorical_accuracy: 0.9823
Epoch 13/50
687/687 [==============================] - 16s 23ms/step - loss: 0.0026 - sparse_categorical_accuracy: 0.9994 - val_loss: 0.0051 - val_sparse_categorical_accuracy: 0.9980
Epoch 14/50
687/687 [==============================] - 16s 24ms/step - loss: 0.0068 - sparse_categorical_accuracy: 0.9980 - val_loss: 4.7899e-04 - val_sparse_categorical_accuracy: 1.0000
Epoch 15/50
687/687 [==============================] - 15s 22ms/step - loss: 4.8140e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.9430e-04 - val_sparse_categorical_accuracy: 0.9998
Epoch 16/50
687/687 [==============================] - 16s 24ms/step - loss: 1.9631e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5435e-04 - val_sparse_categorical_accuracy: 1.0000
Epoch 17/50
687/687 [==============================] - 16s 24ms/step - loss: 1.4179e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4343e-04 - val_sparse_categorical_accuracy: 1.0000
Epoch 18/50
687/687 [==============================] - 17s 24ms/step - loss: 0.0033 - sparse_categorical_accuracy: 0.9995 - val_loss: 0.2592 - val_sparse_categorical_accuracy: 0.9330
Epoch 19/50
687/687 [==============================] - 14s 21ms/step - loss: 0.0132 - sparse_categorical_accuracy: 0.9955 - val_loss: 0.0073 - val_sparse_categorical_accuracy: 0.9976
Epoch 20/50
687/687 [==============================] - 14s 21ms/step - loss: 8.4481e-04 - sparse_categorical_accuracy: 0.9999 - val_loss: 6.6530e-05 - val_sparse_categorical_accuracy: 1.0000
End of training model with activation function =  sigmoid
--------------------------------------------------------------------------------------

              precision    recall  f1-score   support

           0       0.92      1.00      0.96       331
           1       1.00      0.95      0.98       432
           2       1.00      1.00      1.00       310
           3       0.78      0.89      0.83       245
           4       0.94      0.92      0.93       498
           5       0.97      1.00      0.99       247
           6       0.87      0.88      0.88       348
           7       0.84      0.94      0.89       436
           8       0.85      0.98      0.91       288
           9       1.00      0.68      0.81       331
          10       1.00      1.00      1.00       209
          11       0.81      0.82      0.81       394
          12       0.69      0.57      0.62       291
          13       1.00      0.88      0.94       246
          14       0.97      0.94      0.96       347
          15       0.93      0.93      0.93       164
          16       0.40      0.45      0.42       144
          17       0.64      0.74      0.69       246
          18       0.82      0.77      0.79       248
          19       0.75      0.73      0.74       266
          20       0.88      0.95      0.92       346
          21       0.90      0.99      0.94       206
          22       0.97      0.93      0.95       267
          23       0.94      0.88      0.91       332

    accuracy                           0.88      7172
   macro avg       0.87      0.87      0.87      7172
weighted avg       0.88      0.88      0.88      7172

Train time(secs) with dropout relu 	117.01991486549377
Train time(secs) with dropout PReLU 	141.09013104438782
Train time(secs) with dropout sigmoid 	324.0808439254761